{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a79ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import librosa \n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "985034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = 'audio dataset/'\n",
    "DESIRED_LABELS = ['go', 'up', 'down', 'right', 'left', 'off', 'on', 'stop']\n",
    "AUDIO_SIGNAL_FILE = 'pkl_files/audio.npy'\n",
    "TARGET_PATH = 'pkl_files/target.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60014582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/down\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/go\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/left\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/off\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/on\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/right\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/stop\n",
      "/media/mahmoud/New Volume/faculty/level2/study/machine learning/audio_preocessing/audio dataset/up\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(DIRECTORY):\n",
    "    if os.path.isdir(os.path.join(DIRECTORY, dir)) and dir in DESIRED_LABELS:\n",
    "        print(os.path.join(DIRECTORY, dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a289c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n",
      "go\n",
      "left\n",
      "off\n",
      "on\n",
      "right\n",
      "stop\n",
      "up\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for dir in os.listdir(DIRECTORY):\n",
    "    if os.path.isdir(os.path.join(DIRECTORY, dir)) and dir in DESIRED_LABELS:\n",
    "        \n",
    "        for file in os.listdir(os.path.join(DIRECTORY, dir)):\n",
    "            wave, sr = librosa.load(os.path.join(DIRECTORY, dir, file))\n",
    "            X.append(wave)\n",
    "            y.append(dir)\n",
    "        print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a9074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24779/2779150424.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(X)\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46edaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(AUDIO_SIGNAL_FILE, X, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959d081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TARGET_PATH, delimiter=',', X=y, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34592f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.Series(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01995f2",
   "metadata": {},
   "source": [
    "# Fill Non 1 sec Signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad84e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = X.apply(lambda x : len(x) / 22050)\n",
    "\n",
    "idx = period[period<1.0].index\n",
    "\n",
    "df = X[idx]\n",
    "\n",
    "df = df.apply(lambda x : np.append(x, np.zeros(22050-len(x))))\n",
    "\n",
    "X[idx] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72a82308",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(AUDIO_SIGNAL_FILE, X, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
